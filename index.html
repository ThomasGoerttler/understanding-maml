<!DOCTYPE html>
<html>
	<head>
		<title>Visual Comparison of Model-Agnostic Meta-Learning üë©‚Äçüî¨</title>
		<meta charset="UTF-8"/>
		<link rel="stylesheet" href="build/bundle.css">
  </head>
  <body>
    <script async src="https://distill.pub/template.v1.js"></script>
    <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
    <script defer src="build/bundle.js"></script>

<script type="text/front-matter">
  title: "Visual Comparison of Model-Agnostic Meta-Learning"
  description: "t.b.d."
  authors:
  - Luis M√ºller: https://github.com/pupuis
  - Max Ploner:
  affiliations:
  - NI @ TU Berlin: https://www.ni.tu-berlin.de/menue/neural_information_processing_group/
  - NI @ TU Berlin: https://www.ni.tu-berlin.de/menue/neural_information_processing_group/
</script>

<dt-article>
	<h1>A Visual Comparison of Model-Agnostic Meta-Learning</h1>
	<h2>Exploring the world of model-agnostic meta-learning and its extensions.</h2>
	<figure class="l-page">
    <d-figure id="teaser">
			<div class="element is-loading" style="height: 400px"></div>
		</d-figure>
		<figcaption>
			Click button or drag sample onto example to classify the sample.
		</figcaption>
  </figure>

	<dt-byline></dt-byline>

	<p>
		If you tried the little exercise above, you probably got a pretty good score.
		Even though you probably have never seen some of the characters,
		you are able to compare them to a another one, potentially without realizing
		that what you are doing is actually pretty impressive!
	</p>

	<figure class="l-page side">
    <d-figure id="fewShotMethods">
			<div class="element is-loading" style="height: 400px"></div>
		</d-figure>
		<figcaption>
			<p>Results of different methods on the omniglot dataset.</p>
			<ul>
				<li><span id="generative_stroke_model" class="fewShotMethods-reference">
						Test
				</span></li>
			</ul>
		</figcaption>
  </figure>




  <p>In the last years, Meta-learning has aroused the interest of many different research fields in machine learning. Especially model-agnostic meta-learning <dt-cite key="finn2017modelagnostic"></dt-cite> is a fascinating approach. Many different extensions have been proposed to improve training.
  This project should compare these different approaches. It is the goal of this article to make it visually as understandable as possible.</p>
  <p>If we want to use equations we can either write inline, e.g. saying that we intitalize \(\alpha = 0.01\), or in its own paragraph, e.g. saying we then learn our updates via
    \[ \theta_i' = \theta - \alpha \nabla_\theta \mathcal{L}_{\mathcal{T}_i} (f_\theta) .\]

  You can implement this in python as follows:
	</p>
  <dt-code block language="python">
      def step(theta, alpha, model, data):
          return theta - alpha * model.grad(data)
  </dt-code>



	<p>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam eget nisi in tortor maximus feugiat id et massa. In eu pulvinar sapien, eget tincidunt massa. Praesent enim nibh, sagittis nec magna nec, tempus rhoncus metus. Vestibulum rutrum eget tortor sit amet consequat. Curabitur arcu justo, vulputate ut turpis eu, mattis viverra orci. Duis tincidunt ullamcorper mauris ut euismod. Nulla a enim in felis tempus varius. Phasellus sapien sem, viverra sit amet hendrerit a, facilisis a ex. Nulla felis quam, suscipit sed molestie nec, blandit ac ipsum. Quisque viverra tellus nec odio volutpat auctor. Sed sit amet sem luctus sapien efficitur sodales. Quisque dui mi, posuere sed vehicula vel, dapibus quis metus. Integer malesuada tristique massa, nec pellentesque tellus vestibulum sit amet. Donec et bibendum purus, non dignissim magna. Maecenas augue orci, consectetur eu volutpat sed, rutrum id nisl.
	</p>
	<figure class="l-page side">
    <d-figure id="contourExample"><div class="element is-loading" style="height: 400px"></div></d-figure>
  </figure>

	<p>
Praesent varius ut augue quis commodo. Donec euismod, ligula in porta pulvinar, diam metus volutpat libero, a iaculis urna quam quis mauris. Nam mi elit, placerat nec posuere non, posuere a dui. Praesent aliquam lacus dolor, ut vulputate tortor egestas eget. Sed libero sem, ultrices eget arcu et, lobortis dapibus quam. Duis facilisis erat dui, ullamcorper sodales risus placerat id. Cras vel risus scelerisque, blandit sem ac, pharetra urna. Integer eget ipsum vel purus pharetra condimentum. Donec eget quam bibendum metus tincidunt lacinia eget a neque. Nullam faucibus vehicula fringilla. Mauris vitae metus velit. Vivamus at mauris neque. Sed non leo vel dolor finibus blandit.
	</p>

	<figure class="l-body">
    <d-figure id="metaGradient"><div class="element is-loading" style="height: 400px"></div></d-figure>
  </figure>

	<figure class="l-body-outset">
	<d-figure id="userOptimizedTheta"><div class="element is-loading" style="height: 400px"></div></d-figure>
	</figure>

</dt-article>

<dt-appendix>
</dt-appendix>


<script type="text/bibliography">
@misc{finn2017modelagnostic,
    title={Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
    author={Chelsea Finn and Pieter Abbeel and Sergey Levine},
    year={2017},
    eprint={1703.03400},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
		url={https://arxiv.org/abs/1703.03400},
}
</script>
  </body>
</html>
