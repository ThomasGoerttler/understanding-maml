<!DOCTYPE html>
<html>

<head>
	<title>An Interactive Introduction to Model-Agnostic Meta-Learning üë©‚Äçüî¨</title>
	<meta charset="UTF-8" />
	<link rel="stylesheet" href="build/bundle.css">
</head>

<body>
	<script async src="https://distill.pub/template.v2.js"></script>
	<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

	<script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
	<script defer src="build/bundle.js"></script>

	<d-front-matter>

		<script type="text/json">
			{
				"title": "An Interactive Introduction to Model-Agnostic Meta-Learning",
				"description": "Exploring the world of model-agnostic meta-learning and its extensions.",
				"authors": [
					{
						"author":"Luis M√ºller",
						"authorURL":"https://github.com/pupuis",
						"affiliations": [
							{"name": "NI @ TU Berlin", "url": "https://www.ni.tu-berlin.de/menue/neural_information_processing_group/"}
						]
					},
					{
						"author":"Max Ploner",
						"authorURL":"https://maxploner.de",
						"affiliations": [
							{"name": "NI @ TU Berlin", "url": "https://www.ni.tu-berlin.de/menue/neural_information_processing_group/"},
							{"name": "ML @ HU Berlin", "url": "https://www.informatik.hu-berlin.de/en/forschung-en/gebiete/ml-en"}
						]
					}
				]
			}

		</script>
	</d-front-matter>

	<d-title>
		<!--<h1>An Interactive Introduction to Model-Agnostic Meta-Learning</h1>-->
		<!--<h2>Exploring the world of model-agnostic meta-learning and its extensions.</h2>-->
		<figure class="l-page" style="border-top: 1px solid hsla(0, 0%, 0%, 0.1);">
			<d-figure id="teaser">
				<div class="element is-loading" style="height: 400px"></div>
			</d-figure>
			<figcaption>
				<p style="font-size: 1.5em; margin-bottom: 1.2rem; margin-top: 1.5em">
					<i><b>MAML</b> learns tasks like the ones above by aciquiring meta-knowledge about similar problems.</i>
				</p>
				<p>
					What you have in front of you is a 5- or 20-way-1-shot problem, one that most conventional machine
					learning
					systems struggle to solve.
					To classify a sample (top), either drag it to or click on the desired class (bottom) and see if you can
					do better. To switch between 5-way and 20-way (which decides how many classes are available), use the
					drop-down menu on the top
					right.
				</p>
			</figcaption>
		</figure>
	</d-title>

	<d-byline></d-byline>

	<d-article>

		<p>
			<i style="font-size: .8em;">
				This page is part of a multi-part series on Model-Agnostic Meta-Learning.
				If you are already familiar with the topic, use the menu on the right
				side to jump straight to the part that is of interest for you. Otherwise,
				we suggest you start at the <a href="./">beginning</a>.
			</i>
		</p>

		<aside id="menu" class="menu">
			<div class="element is-loading" style="height: 400px"></div>
		</aside>


		<p>
			If you tried the exercise above, you have undoubtedly received a very high accuracy score.
			Even though you likely have never seen some of the characters,
			you are able to classify them given only a single example, potentially
			without realizing that what you are able to do off the top of your head would be pretty impressive to the
			average
			Deep Neural Net!
		</p>
		<p>
			In this article we would like to give you an interactive introduction to
			Model-Agnostic Meta-Learning,
			a research field
			that attempts to equip conventional machine learning architectures with the power to gain meta-knowledge
			about a range of
			tasks in order to solve problems like the one above on a human level of accuracy.
		</p>

		<h3>Getting Started</h3>
		<p>
			A common wisdom shared across the machine learning community is the need to train models on a truck-load of
			samples before they are able to
			make meaningful predictions on unseen data. But we do not always have enough data available to
			cater this need: A sufficient amount of data may be expensive or even
			impossible to acquire.
			Yet, there are good reasons to believe that this is not an inherent issue
			of learning.
			Humans, such as yourself, are known to excel at generalizing after seeing only a few
			samples <d-cite bibtex-key="salakhutdinov_one-shot_nodate"></d-cite>.
			It should, however, also be noted that humans do not learn
			novel concepts "in a vacuum"<d-cite bibtex-key="lake_one_2011"></d-cite> but based off a lot of prior
			knowledge.
			Enabling machine learning methods to achieve the same would bring us a step closer to learning on the data-
			and energy-efficiency
			level of humans. Consequently we would require algorithms to do the following two things, already
			successfully implemented in humans:
		</p>
		<ul>
			<li>(a) Obtaining as much prior knowledge about the world as possible and</li>
			<li>(b) using that to generalize well on only a few samples.</li>
		</ul>
		<p>
			The method we present in this article has prominently emerged from research
			in two fields which each address one of the above requirements. While introducing these fields to you, we
			will
			also equip you with the most important terms and concepts we will need along the rest of the article.
		</p>

		<h4>(a) Obtaining Prior Knowledge</h4>
		<p>
			While clearly one sample is not enough for a model without prior knowledge,
			we can pretrain models on tasks that we assume to be similar to the target tasks.
			The idea in its core is to derive an inductive bias
			from a set of problem-classes in order to perform better on other, newly encountered, problem-classes.
			This similarity assumption allows the model to collect meta-knowledge:
			knowledge which is not obtained from a single task, but from a distribution of tasks.
			The learning of this meta-knowledge is called "meta-learning".
		</p>

		<h4>(b) Generalization on a Few Samples</h4>
		<p>
			Achieving rapid convergence of machine learning models on but a few samples is known as
			"few-shot learning". If you are presented with \(N\) samples and are expected to learn a classification
			problem with \( M \)
			classes, we speak of an \( M \)-way-\(N\)-shot problem.
			The exercise at the top of the article, which we offer either as a \(20\)- or \(5\)-way-1-shot problem, is a
			prominent example of a few-shot learning task, whose symbols are
			taken from
			the <d-cite bibtex-key="lake_omniglot_2015"><i>omniglot</i> dataset</d-cite>.
			It contains 1623 different characters across 50 alphabets with each character
			being represented by 20 instances, each drawn by a different person. Because of that, the original authors
			of the omniglot dataset
			described it as a "transpose" of the well-known MNIST dataset <d-cite bibtex-key="lake_one_2011"></d-cite>,
			with MNIST containing only a few classes (the digits 0 to 9) and many instances and omniglot containing a
			lot of classes but only a few instances for each.
		</p>


		<figure class="l-page side">
			<d-figure id="fewShotMethods">
				<div class="element is-loading" style="height: 400px"></div>
			</d-figure>
			<figcaption>
				<p>Results of different methods on the omniglot dataset
					(if not stated differently: 1-shot, 20-way;
					some differences in the evaluation procedure exist).
					As usual, accuracy numbers need to be taken with a grain of salt as
					differences in the evaluation method, implementation, and the model
					complexity may a have a non-negligible impact on the performance.
				</p>
				<p id="caption_generative_stroke_model" class="fewShotMethods-reference">
					The generative stroke model was introduced in the paper which also
					introduced omniglot. The model is based on a latent stroke representation
					(including the number and directions of strokes). While it is an
					interesting approach, it can hardly be generalized to other
					few-shot problems.<d-cite bibtex-key="lake_one_2011"></d-cite>
				</p>
				<p id="caption_hierachical_bayesian_program_learning" class="fewShotMethods-reference">
					The same authors improved the model by learning latent
					primitive motor elements and called this process "Hierarchial
					Bayesian Program Learning" (HBPL).
					While the accuracy was greatly increased, it also
					is focused on symbol learning.
					<d-cite bibtex-key="lake_one-shot_2013"></d-cite>
				</p>
				<p id="caption_siamese_nets" class="fewShotMethods-reference">
					Siames Nets consist of two identical networks which produce a latent representation.
					From the representations of two samples, a distance is calculated to
					assess the similarity of the two samples.<d-cite bibtex-key="koch_siamese_2015"></d-cite>
					The result (accuracy of 88.1%) results from a reimplementaion of the method which
					makes it more comparable.
					<d-cite bibtex-key="vinyals_matching_2017"></d-cite>
				</p>
				<p id="caption_matching_nets" class="fewShotMethods-reference">
					Matching Networks also work by comparing new samples to labeled
					examples. They do so by utilizing an attention kernel.
					Though the second version of the paper is cited here,
					it was first published in 2016.
					<d-cite bibtex-key="vinyals_matching_2017"></d-cite>
				</p>

				<p id="caption_prototypical_networks" class="fewShotMethods-reference">
					Prototypical Networks use prototype vectors to represent each class
					in the metric space. The nearest neighbor (i.e. the closest prototype)
					of a sample then determines the prediction.
					<d-cite bibtex-key="snell_prototypical_2017"></d-cite>
				</p>

				<p id="caption_memory_augmented_nets" class="fewShotMethods-reference">
					Memory-Augmented Networks (MANNs) use an external memory to make accurate
					predictions using a small number of samples.
					<d-cite bibtex-key="santoro_meta-learning_2016"></d-cite>
				</p>

				<p id="caption_meta_nets" class="fewShotMethods-reference">
					Meta Networks utilize a base learner (task level) and a meta learner
					as well as a set of slow and rapid weights in order to allow
					meta learning as well as task-specific concepts.
					<d-cite bibtex-key="munkhdalai_meta_2017"></d-cite>
				</p>

			</figcaption>
		</figure>


		<p>
			Having set the scene, we can now dig into MAML and its
			extensions. Continue reading on this page to find out why MAML is called
			"model-agnostic",
			go straight to an explanation of <a href="maml.html">MAML</a>,
			or navigate straight to the part you are most interested in using the <a href="#menu">menu at the top</a>.
		</p>


		<h2>Why MAML is Model-Agnostic</h2>
		<p>
			In the figure on the right you can find a selection of meta-learning methods
			that tackle
			few-shot
			learning, their performance on <i>omniglot</i> as well as your own accuracy score from exercise above.
			Model-Agnostic Meta-Learning (short: "MAML", marked in <span style="color: #d62728">red</span>)
			is the only one among the above methods that falls under the category of
			<i>optimization-based meta-learning</i>, which will be our main interest in the rest of the article.
		</p>


		<figure class="l-page side">
			<d-figure id="fewShotVenn">
				<div class="element is-loading" style="height: 300px"></div>
			</d-figure>
			<figcaption>
				<p id="caption_lstm_based" class="fewShotMethods-reference">
					Applications of Meta-Learning outside the domain of few-shot learning
					include the optimization of the task-level optimizer using
					a LSTM network.
					<d-cite bibtex-key="andrychowicz_learning_2016"></d-cite>
				</p>
			</figcaption>
		</figure>



		<p>
			Before we get started with the explanation of how MAML works,
			we want to take a moment to look at what is Model-Agnostic about MAML.
			In order to understand, why this method is called "model-agnostic", we need
			to look at how the few-shot problem was tackled by other approaches.
			While there are methods, which try to mitigate the issues introduced by the
			the few-shot constraint, many do resort to adopting the meta-learning
			assumption. These methods can broadly be divided into two classes:
			metric-based and model-based approaches.
		</p>
		<p>
			The core idea of metric-based approaches is to compare two samples in a
			latent (metric) space: In this space, samples of the same class are supposed
			to be close to each other, while two samplese from different classes are
			supposed to have a large distance (the notion of a distance is what makes
			the latent space a metric space).
			<d-cite bibtex-key="snell_prototypical_2017"></d-cite>
			<d-cite bibtex-key="koch_siamese_2015"></d-cite>
			<d-cite bibtex-key="vinyals_matching_2017"></d-cite>
		</p>
		<p>
			Model-based approaches are neural architectures which are deliberately designed
			for fast adaption to new tasks without inclining to overfit.
			Memory-Augmented Neural Networks and MetaNet are two examples. Both employ
			an external memory while still maintaining the ability to be trained
			end-to-end.
			<d-cite bibtex-key="santoro_meta-learning_2016"></d-cite>
			<d-cite bibtex-key="munkhdalai_meta_2017"></d-cite>
		</p>

		<p>
			MAML goes a different route: The neural network is designed the same way
			your usual model might be (in the many-shot case). All the magic happens during the
			optimization. Hence, it is called "optimization-based".
			Unlike, metric-based and model-based approaches, MAML lets
			you choose the model architecture as you like.
			This has the great benefit of being applicable can not only for
			classical supervised learning classification tasks but can also
			for reinforcement learning.
			<d-cite bibtex-key="finn2017modelagnostic"></d-cite>
		</p>
		<p>
			Go to <a href="maml.html">the next part</a>, to learn how this is achieved
			or jump <a href="#menu">menu at the top</a> to navigate to the parts your
			are most interested in.
		</p>

	</d-article>

	<d-appendix>
	</d-appendix>


	<script type="text/bibliography">


</script>
</body>

</html>
