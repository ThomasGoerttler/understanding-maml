<!DOCTYPE html>
<html>
	<head>
		<title>Visual Comparison of Model-Agnostic Meta-Learning üë©‚Äçüî¨</title>
		<meta charset="UTF-8"/>
		<link rel="stylesheet" href="build/bundle.css">
  </head>
  <body>
    <script async src="https://distill.pub/template.v1.js"></script>
    <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
    <script defer src="build/bundle.js"></script>

<script type="text/front-matter">
  title: "Visual Comparison of Model-Agnostic Meta-Learning"
  description: "t.b.d."
  authors:
  - Luis M√ºller: https://github.com/pupuis
  - Max Ploner:
  affiliations:
  - NI @ TU Berlin: https://www.ni.tu-berlin.de/menue/neural_information_processing_group/
  - NI @ TU Berlin: https://www.ni.tu-berlin.de/menue/neural_information_processing_group/
</script>

<dt-article>
	<h1>A Visual Comparison of Model-Agnostic Meta-Learning</h1>
	<h2>Exploring the world of model-agnostic meta-learning and its extensions.</h2>
	<figure class="l-page">
    <d-figure id="teaser">
			<div class="element is-loading" style="height: 400px"></div>
		</d-figure>
		<figcaption>
			Click button or drag sample onto example to classify the sample.
		</figcaption>
  </figure>

	<dt-byline></dt-byline>

	<p>
		If you tried the little exercise above, you probably got a pretty good score.
		Even though you probably have never seen some of the characters,
		you are able to compare them to a another one, potentially without realizing
		that what you are doing is actually pretty impressive!
	</p>

	<figure class="l-page side">
    <d-figure id="fewShotMethods">
			<div class="element is-loading" style="height: 400px"></div>
		</d-figure>
		<figcaption>
			<p>Results of different methods on the omniglot dataset.</p>
			<ul>
				<li><span id="generative_stroke_model" class="fewShotMethods-reference">
						Test
				</span></li>
			</ul>
		</figcaption>
  </figure>

	<p>
		Typically, in machine learning we need a lot of examples to be able to
		classify a class. But not always do we have enough data to cater this need:
		a sufficient amount of data may be expensive or even impossible to acquire.
		But there is good reasons to believe, that this is not an inherent issue of learning.
		Humans, for example, are quite good at generalizing after seeing only a few
		samples. Enabling machine learning methods to achieve the same would allow
		for many new applications and generally reduce the need to collect huge
		datasets.[<b>reference needed</b>]
	</p>

	<p>
		This research area is called "few-shot learning". It aims to enable models
		to classify unseen sampels after training only one a few examples ("shots").
		The little exercise at the top of the article is an exmaple of such a task.
		The symbols are part of a dataset called "omniglot" [<b>reference needed</b>].
		It contains 1623 different characters across 50 alphabets and each character
		has 20 instances drawn by different people. Because of that, the omniglot
		was described as a "transpose" of the well-known MNIST dataset, by the authors
		who originally proposed omniglot as a machine learning dataset. [<b>reference needed</b>]
		While MNIST contains only a few classes (the digits 0 to 9) and many instances,
		of each class, with omniglot it is vice-versa.
	</p>




  <p>In the last years, Meta-learning has aroused the interest of many different research fields in machine learning. Especially model-agnostic meta-learning <dt-cite key="finn2017modelagnostic"></dt-cite> is a fascinating approach. Many different extensions have been proposed to improve training.
  This project should compare these different approaches. It is the goal of this article to make it visually as understandable as possible.</p>

  <h2>Few-shot learning with MAML</h2>
  <p>To get familiar with the problem and also to motivate the need for meta-learning we start with something you probably already know
    and develop it to something new. If you have done machine learning before you have probably already solved or attempted to solve a
    trivial special case of meta-learning: Learning a model to solve one specific task, for example to classify images or to teach an agent
    to find its way through a maze. In those settings, if we are able to define a loss \(\mathcal{L}_\tau\) for our task \(\tau\) which depends on the parameters
    \(\phi\) of a model, we can express our learning objective as

    \[ \underset{\phi}{\text{min}} \, \mathcal{L}_\tau (\phi) .\]

    We usually find the optimal \(\phi\) by progressively walking along the direction of the gradient of
    \(\mathcal{L}_\tau\) with respect to \(\phi\), i.e.

    \[ \phi \leftarrow \phi - \alpha \nabla_\phi \mathcal{L}_\tau (\phi) ,\]

    also known as gradient descent, where \(\mathcal{L}_\tau\) usually also depends on some data and \(\alpha\) is a fixed learning rate,
    controlling the size of the steps we want to take.
  </p>
  <p>We will now make an additional assumption, namely that \(\tau\) comes from some distribution of tasks \(p(\tau)\) and that we
    can sample freely from this distribution. We can then generalize the above objective to learn how to find an
    optimization strategy for a randomly sampled task from \(p(\tau)\). If we additionally ensure that the optimization strategy requires observing only
    a few samples from this task, we
    would have come up with a solution to few-shot learning for tasks from \(p(\tau)\). We
    can express our new learning objective as follows:

    \[ \text{min} \, \mathbb{E}_\tau [ \mathcal{L}_\tau (\phi_\tau) ] ,\]

    where \(\tau\) is now a random variable and \(\phi_\tau\) are a set of parameters for task \(\tau\), which is nothing more than a practical way to formalize really.
    We may use different parameters for each task, use the same parameters for every task or something in between. But anyway, how
    are we actually minimizing this new objective? In the following we will explore two possible answers to this question.
  </p>
  <h3>Answer 1: Just do gradient descent, silly!</h3>
  <p>Of course! The answer to most problems. We can simply learn a single set of parameters \(\phi\) which minimizes the expected loss
    over all tasks. Or formally speaking our objective becomes

    \[ \underset{\phi}{\text{min}} \, \mathbb{E}_\tau [ \mathcal{L}_\tau (\phi) ] .\]

    Further, to actually implement this strategy we can do what is known as <i>Expected Risk Minimization (ERM)</i>, which roughly
    dictates us to sample a lot of tasks \(\tau\) and then descent according to

    \[ \phi \leftarrow \phi - \alpha \nabla_\phi \sum_i \mathcal{L}_{\tau_i} (\phi) .\]

    To make this a bit more robust we can also use an optimizer using an adaptive step size, e.g. <i>Adam</i>. In the following figure
    you can experiment with a model that was trained in exactly this way.
  </p>

  <figure>
    <d-figure id="fitSinePretrained"></d-figure>
  </figure>


  <p>If we want to use equations we can either write inline, e.g. saying that we intitalize \(\alpha = 0.01\), or in its own paragraph, e.g. saying we then learn our updates via
    \[ \theta_i' = \theta - \alpha \nabla_\theta \mathcal{L}_{\mathcal{T}_i} (f_\theta) .\]

  You can implement this in python as follows:
	</p>
  <dt-code block language="python">
      def step(theta, alpha, model, data):
          return theta - alpha * model.grad(data)
  </dt-code>



	<p>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam eget nisi in tortor maximus feugiat id et massa. In eu pulvinar sapien, eget tincidunt massa. Praesent enim nibh, sagittis nec magna nec, tempus rhoncus metus. Vestibulum rutrum eget tortor sit amet consequat. Curabitur arcu justo, vulputate ut turpis eu, mattis viverra orci. Duis tincidunt ullamcorper mauris ut euismod. Nulla a enim in felis tempus varius. Phasellus sapien sem, viverra sit amet hendrerit a, facilisis a ex. Nulla felis quam, suscipit sed molestie nec, blandit ac ipsum. Quisque viverra tellus nec odio volutpat auctor. Sed sit amet sem luctus sapien efficitur sodales. Quisque dui mi, posuere sed vehicula vel, dapibus quis metus. Integer malesuada tristique massa, nec pellentesque tellus vestibulum sit amet. Donec et bibendum purus, non dignissim magna. Maecenas augue orci, consectetur eu volutpat sed, rutrum id nisl.
	</p>
	<figure class="l-page side">
    <d-figure id="contourExample"><div class="element is-loading" style="height: 400px"></div></d-figure>
  </figure>

	<p>
Praesent varius ut augue quis commodo. Donec euismod, ligula in porta pulvinar, diam metus volutpat libero, a iaculis urna quam quis mauris. Nam mi elit, placerat nec posuere non, posuere a dui. Praesent aliquam lacus dolor, ut vulputate tortor egestas eget. Sed libero sem, ultrices eget arcu et, lobortis dapibus quam. Duis facilisis erat dui, ullamcorper sodales risus placerat id. Cras vel risus scelerisque, blandit sem ac, pharetra urna. Integer eget ipsum vel purus pharetra condimentum. Donec eget quam bibendum metus tincidunt lacinia eget a neque. Nullam faucibus vehicula fringilla. Mauris vitae metus velit. Vivamus at mauris neque. Sed non leo vel dolor finibus blandit.
	</p>

	<figure class="l-body">
    <d-figure id="metaGradient"><div class="element is-loading" style="height: 400px"></div></d-figure>
  </figure>

	<figure class="l-body-outset">
	<d-figure id="userOptimizedTheta"><div class="element is-loading" style="height: 400px"></div></d-figure>
	</figure>

</dt-article>

<dt-appendix>
</dt-appendix>


<script type="text/bibliography">
@misc{finn2017modelagnostic,
    title={Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
    author={Chelsea Finn and Pieter Abbeel and Sergey Levine},
    year={2017},
    eprint={1703.03400},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
		url={https://arxiv.org/abs/1703.03400},
}
</script>
  </body>
</html>
