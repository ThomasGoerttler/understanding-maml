<!DOCTYPE html>
<html>

<head>
	<title>Visual Comparison of Model-Agnostic Meta-Learning üë©‚Äçüî¨</title>
	<meta charset="UTF-8" />
	<link rel="stylesheet" href="build/bundle.css">
</head>

<body>
	<script async src="https://distill.pub/template.v1.js"></script>
	<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
	<script defer src="build/bundle.js"></script>

	<script type="text/front-matter">
  title: "Visual Comparison of Model-Agnostic Meta-Learning"
  description: "t.b.d."
  authors:
  - Luis M√ºller: https://github.com/pupuis
  - Max Ploner:
  affiliations:
  - NI @ TU Berlin: https://www.ni.tu-berlin.de/menue/neural_information_processing_group/
  - NI @ TU Berlin: https://www.ni.tu-berlin.de/menue/neural_information_processing_group/
</script>

	<dt-article>
		<h1>A Visual Comparison of Model-Agnostic Meta-Learning</h1>
		<h2>Exploring the world of model-agnostic meta-learning and its extensions.</h2>
		<figure class="l-page">
			<d-figure id="teaser">
				<div class="element is-loading" style="height: 400px"></div>
			</d-figure>
			<figcaption>
				Click button or drag sample onto example to classify the sample.
			</figcaption>
		</figure>

		<dt-byline></dt-byline>

		<p>
			<i style="font-size: .8em;">
				If you are already familiar with few-shot learning, and are only interested
				in learning about MAML specifically, you may want to skip this section and
				jump straight to the <a href="#few_shot_maml">next part</a>.
			</i>
		</p>

		<p>
			If you tried the little exercise above, you probably got a pretty good score.
			Even though you likely have never seen some of the characters,
			you are able to compare them to a another one, potentially without realizing
			that what you are doing is actually pretty impressive!
		</p>

		<h3>Few-Shot Learning</h3>

		<p>
			Typically, in machine learning we need a lot of examples to be able to
			classify a class. But not always do we have enough data to cater this need:
			a sufficient amount of data may be expensive or even impossible to acquire.
			But there is good reasons to believe, that this is not an inherent issue of learning.
			Humans, for example, are quite good at generalizing after seeing only a few
			samples. Enabling machine learning methods to achieve the same would allow
			for many new applications and generally reduce the need to collect huge
			datasets.[<b>TODO: reference needed</b>]
		</p>

		<p>
			This research area is called "few-shot learning". It aims to enable models
			to classify unseen sampels after training only one a few examples ("shots").
			The little exercise at the top of the article is an exmaple of such a task.
			The symbols are part of a dataset called "omniglot". <dt-cite key="lake_one_2011"></dt-cite>
			It contains 1623 different characters across 50 alphabets and each character
			has 20 instances drawn by different people. Because of that, the omniglot
			was described as a "transpose" of the well-known MNIST dataset, by the authors
			who originally proposed omniglot as a machine learning dataset. <dt-cite key="lake_one_2011"></dt-cite>
			While MNIST contains only a few classes (the digits 0 to 9) and many instances,
			of each class, with omniglot it is vice-versa.
		</p>



		<p>
			By now, you may be asking yourself: How can a model learn from only one example
			(i.e. "one-shot") and why do I even need a dataset like omniglot
			if the model is supposed to learn from one sample?
			While clearly one sample is not enough for a model without prior knowledge,
			we can pretrain models on tasks that we assume to be similar to the target tasks. This is
			the general idea of few-shot learning: derive some inductive bias
			from other classes in order to perform better on newly encountered classes.
			This similarity assumption allows the model to collect meta-knowledge:
			knowledge which does not describe a single task, but a distribution of tasks.
			The learning of this meta-knowledge is referred to as "meta-learning".
		</p>

		<figure class="l-page side">
			<d-figure id="fewShotMethods">
				<div class="element is-loading" style="height: 400px"></div>
			</d-figure>
			<figcaption>
				<p>Results of different methods on the omniglot dataset
					(if not stated differently: 1-shot, 20-way;
					some differences in the evaluation procedure exist).
					As usual, accuracy numbers need to be taken with a grain of salt as
					differences in the evaluation method, implementation, and the model
					complexity may a have a non-negligible impact on the performance.
				</p>
				<p id="caption_generative_stroke_model" class="fewShotMethods-reference">
					The generative stroke model was introduced in the paper which also
					introduced omniglot. The model is based on a latent stroke representation
					(including the number and directions of strokes). While it is an
					interesting approach, it can hardly be generalized to other
					few-shot problems.<dt-cite key="lake_one_2011"></dt-cite>
				</p>
				<p id="caption_hierachical_bayesian_program_learning" class="fewShotMethods-reference">
					The same authors improved the model by learning latent
					primitive motor elements and called this process "Hierarchial
					Bayesian Program Learning" (HBPL).
					While the accuracy was greatly increased, it also
					is focused on symbol learning.
					<dt-cite key="lake_one-shot_2013"></dt-cite>
				</p>
				<p id="caption_siamese_nets" class="fewShotMethods-reference">
					Siames Nets consist of two identical networks which produce a latent representation.
					From the representations of two samples, a distance is calculated to
					assess the similarity of the two samples.<dt-cite key="koch_siamese_2015"></dt-cite>
					The result (accuracy of 88.1%) results from a reimplementaion of the method which
					makes it more comparable.
					<dt-cite key="vinyals_matching_2017"></dt-cite>
				</p>
				<p id="caption_matching_nets" class="fewShotMethods-reference">
					Matching Networks also work by comparing new samples to labeled
					examples. They do so by utilizing an attention kernel.
					Though the second version of the paper is cited here,
					it was first published in 2016.
					<dt-cite key="vinyals_matching_2017"></dt-cite>
				</p>

				<p id="caption_prototypical_networks" class="fewShotMethods-reference">
					Prototypical Networks use prototype vectors to represent each class
					in the metric space. The nearest neighbor (i.e. the closest prototype)
					of a sample then determines the prediction.
					<dt-cite key="snell_prototypical_2017"></dt-cite>
				</p>

				<p id="caption_memory_augmented_nets" class="fewShotMethods-reference">
					Memory-Augmented Networks (MANNs) use an external memory to make accurate
					predictions using a small number of samples.
					<dt-cite key="santoro_meta-learning_2016"></dt-cite>
				</p>

				<p id="caption_meta_nets" class="fewShotMethods-reference">
					Meta Networks utilize a base learner (task level) and a meta learner
					as well as a set of slow and rapid weights in order to allow
					meta learning as well as task-specific concepts.
					<dt-cite key="munkhdalai_meta_2017"></dt-cite>
				</p>

			</figcaption>
		</figure>

		<figure class="l-page side">
			<d-figure id="fewShotVenn">
				<div class="element is-loading" style="height: 300px"></div>
			</d-figure>
			<figcaption>
				<p id="caption_lstm_based" class="fewShotMethods-reference">
					Applications of Meta-Learning outside the domain of few-shot learning
					include the optimization of the task-level optimizer using
					a LSTM network.
					<dt-cite key="andrychowicz_learning_2016"></dt-cite>
				</p>
			</figcaption>
		</figure>



		<p>
			Plenty of methods have been proposed in the last years to tackle few-shot
			learning using the meta-learning assumption,
			and many are able to produce decent results.
			In this article, we will focus
			on one of them: "Model-Agnostic Meta-Learning" (MAML).
		</p>

		<h3>Model-Agnostic Meta-Learning</h3>

		<p>
			Before we get started with the explanation of how MAML works,
			we want to take a moment to look at what is Model-Agnostic about MAML.
			In order to understand, why this method is called "model-agnostic", we need
			to look at how the few-shot problem was tackled by other approaches.
			While there are methods, which try to mitigate the issues introduced by the
			the few-shot constraint, many do resort to adopting the meta-learning
			assumption. These methods can broadly be divided into two classes:
			metric-based and model-based approaches.
		</p>
		<p>
			The core idea of metric-based approaches is two compare two samples in a
			latent (metric) space: In this space, samples of the same class are supposed
			to be close to each other, while two samplese from different classes are
			supposed to have a large distance (the notion of a distance is what makes
			the latent space a metric space).
			<dt-cite key="snell_prototypical_2017"></dt-cite>
			<dt-cite key="koch_siamese_2015"></dt-cite>
			<dt-cite key="vinyals_matching_2017"></dt-cite>
		</p>
		<p>
			Model-based approaches are neural architectures which are deliberately designed
			for fast adaption to new tasks without inclining to overfit.
			Memory-Augmented Neural Networks and MetaNet are two examples. Both employ
			an external memory while still maintaining the ability to be trained
			end-to-end.
			<dt-cite key="santoro_meta-learning_2016"></dt-cite>
			<dt-cite key="munkhdalai_meta_2017"></dt-cite>
		</p>

		<p>
			MAML goes a different route: The nerual network is designed the same way
			your usual model might be (in the many-shot case). All the magic happens during the
			optimization. Hence, it is called "optimization-based".
			Unlike, metric-based and model-based approaches, MAML lets
			you choose the model architecture as you like.
			This has the great benefit of being applicable can not only for
			classical supervised learning classification tasks but can also
			for reinforcement learning.
			<dt-cite key="finn2017modelagnostic"></dt-cite>
		</p>
		<p>
			In the next seciton, you will learn how this is achieved.
		</p>

		<h2 id="few_shot_maml">Few-shot learning with MAML</h2>
		<p>Model-Agnostic Meta Learning is a meta-learning approach to solve few-shot learning. We are now going to have
			a look at the method and see what makes it <i>meta</i>.
			But before we see the method unfold, take a look at the following setting: If you have done machine learning
			before you have probably already solved or attempted to solve such a problem:
			Learning a model to solve one specific task, for example to classify a specific collection of images or to
			teach an agent
			to find its way through a specific maze. In those settings, if we are able to define a loss
			\(\mathcal{L}_\tau\) for our task \(\tau\) which depends on the parameters
			\(\phi\) of a model, we can express our learning objective as

			\[ \underset{\phi}{\text{min}} \, \mathcal{L}_\tau (\phi) .\]

			We usually find the optimal \(\phi\) by progressively walking along the direction of the gradient of
			\(\mathcal{L}_\tau\) with respect to \(\phi\), i.e.

			\[ \phi \leftarrow \phi - \alpha \nabla_\phi \mathcal{L}_\tau (\phi) ,\]

			also known as gradient descent, where \(\mathcal{L}_\tau\) usually also depends on some data and \(\alpha\)
			is a fixed learning rate,
			controlling the size of the steps we want to take.
		</p>
		<p>Unfortunately, when framing this in a few-shot setting (i.e., with a very small dataset), the above method is
			known to fail almost certaintly [REF]. A key insight to MAML is now to
			bypass this problem by learning not only from the data regarding exactly our task, but to learn also from
			data of similar tasks.
			To incorporate this we make an additional assumption, namely that \(\tau\) comes from some distribution of
			tasks \(p(\tau)\) and that we
			can sample freely from this distribution. We can then generalize the above objective to learn how to find an
			optimization strategy for a randomly sampled task from \(p(\tau)\), which we can express as follows:

			\[ \text{min} \, \mathbb{E}_\tau [ \mathcal{L}_\tau (\phi_\tau) ] ,\]

			where \(\tau\) is now a random variable and \(\phi_\tau\) are a set of parameters for task \(\tau\).
			We may use different parameters for each task, use the same parameters for every task or something in
			between. So we have to decide on a parameterization and decide how we actually minimize this new objective.
			In the following we will explore two possible
			answers to these issues.
		</p>
		<h3>Answer 1: Just do gradient descent, silly!</h3>
		<p>Of course! The answer to most problems. We can simply learn a single set of parameters \(\phi\) which
			minimizes the expected loss
			over all tasks. Or formally speaking our objective becomes

			\[ \underset{\phi}{\text{min}} \, \mathbb{E}_\tau [ \mathcal{L}_\tau (\phi) ] .\]

			As you can see we choose the most simple parameterization: We learn one parameter vector \(\phi\) that minimizes the objective 
			across all tasks.
			Further, to actually implement this strategy we can do what is known as <i>Expected Risk Minimization
				(ERM)</i>, which roughly
			dictates us to sample a lot of tasks \(\tau\) and then descent according to

			\[ \phi \leftarrow \phi - \alpha \nabla_\phi \sum_i \mathcal{L}_{\tau_i} (\phi) .\]

			To make this a bit more robust we can also use an optimizer using an adaptive step size, e.g. <i>Adam</i>.
			Finn et al. call this model <i>pretrained</i>.
			In the following figure you can experiment with <i>pretrained</i> model which was trained by a collection of
			sinusoid regression tasks. Before you fit the model think what
			you would expect to happen based on the position and the
			amount of samples you provided. Feel free to also experiment with the different settings: Distributing the
			samples equispaced or squeezing all of them to a small range
			of the x-axis.
		</p>

		<figure>
			<d-figure id="fitSinePretrained"></d-figure>
		</figure>
		<p>Ouch! That doesn't seem to work that well. Maybe you have already guessed that this would have been to easy.
			The problem that the above approach faces is that the optimal parameters of
			different tasks might live in completely different loss spaces. Take for example the following two tasks
			(which were probably both part of the training set of the <i>pretrained</i> model):
			Tasks \(\tau_1, \tau_2\) are both regression tasks on sinusoids \(y_1(x) := \sin (x - \frac{\pi}{2})\) and
			\(y_2(x) := \sin (x + \frac{\pi}{2})\) respectively. These two tasks will
			give the <i>pretrained</i> model completely contradicting information as

			\[ y_1(x) = - y_2(x) \].

			Intuitively this is because the vanilla gradient descent approach is always just fitting one particular
			function (of which we assume not have enough data) and thus fails upon receiving information
			that does not stem from said function. However, despite these two functions contradicting each other in the gradient descent setting  
			does not mean they do not agree in other ways. Looking at the two functions in the above figure they clearly represent the same structure, 
			merely shifted by an amount of \(\pi\). This indicates that maybe we can learn from one of the tasks about the other one after all.
			Maybe answer 2 will do...
		</p>

		<h3>Just do Model-Agnostic Meta-Learning, silly!</h3>
		<p>
			MAML comes to our rescue. We have already seen how different tasks might give us contradicting function values at the same query point. The idea of MAML is now to 
			learn an optimal initialization \(\theta\) in the sense that initializating a task optimizer with these parameters and taking gradient descent steps 
			from there minimizes the loss for that task. We can express this formally as follows:

			\[ \underset{\theta}{\text{min}} \, \mathbb{E}_\tau [ \mathcal{L}_\tau (U_\tau(\theta)) ] .\]

			where \(U_\tau\) is an optimizer that takes a number of gradient descent steps given the samples of task \(\tau\).
		</p>

		<dt-code block language="python">
			def step(theta, alpha, model, data):
			return theta - alpha * model.grad(data)
		</dt-code>

		<figure class="l-body">
			<d-figure id="metaGradient">
				<div class="element is-loading" style="height: 400px"></div>
			</d-figure>
		</figure>

		<figure class="l-body-outset">
			<d-figure id="userOptimizedTheta">
				<div class="element is-loading" style="height: 400px"></div>
			</d-figure>
		</figure>

	</dt-article>

	<dt-appendix>
	</dt-appendix>


	<script type="text/bibliography">
@misc{finn2017modelagnostic,
    title={Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
    author={Chelsea Finn and Pieter Abbeel and Sergey Levine},
    year={2017},
    eprint={1703.03400},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
		url={https://arxiv.org/abs/1703.03400},
}


@article{lake_one_2011,
	title = {One shot learning of simple visual concepts},
	abstract = {People can learn visual concepts from just one example, but it remains a mystery how this is accomplished. Many authors have proposed that transferred knowledge from more familiar concepts is a route to one shot learning, but what is the form of this abstract knowledge? One hypothesis is that the sharing of parts is core to one shot learning, and we evaluate this idea in the domain of handwritten characters, using a massive new dataset. These simple visual concepts have a rich internal part structure, yet they are particularly tractable for computational models. We introduce a generative model of how characters are composed from strokes, where knowledge from previous characters helps to infer the latent strokes in novel characters. The stroke model outperforms a competing stateof-the-art character model on a challenging one shot learning task, and it provides a good Ô¨Åt to human perceptual data.},
	language = {en},
	author = {Lake, Brenden M and Salakhutdinov, Ruslan and Gross, Jason and Tenenbaum, Joshua B},
	year = {2011},
	url = {https://cims.nyu.edu/~brenden/LakeEtAl2011CogSci.pdf},
}


@article{lake_one-shot_2013,
	title = {One-shot learning by inverting a compositional causal process},
	abstract = {People can learn a new visual class from just one example, yet machine learning algorithms typically require hundreds or thousands of examples to tackle the same problems. Here we present a Hierarchical Bayesian model based on compositionality and causality that can learn a wide range of natural (although simple) visual concepts, generalizing in human-like ways from just one image. We evaluated performance on a challenging one-shot classiÔ¨Åcation task, where our model achieved a human-level error rate while substantially outperforming two deep learning models. We also tested the model on another conceptual task, generating new examples, by using a ‚Äúvisual Turing test‚Äù to show that our model produces human-like performance.},
	language = {en},
	author = {Lake, Brenden M and Salakhutdinov, Ruslan},
	year = {2013},
	url = {https://cims.nyu.edu/~brenden/LakeEtAlNips2013.pdf}
}



@article{koch_siamese_2015,
	title = {Siamese Neural Networks for One-shot Image Recognition},
	abstract = {The process of learning good features for machine learning applications can be very computationally expensive and may prove difÔ¨Åcult in cases where little data is available. A prototypical example of this is the one-shot learning setting, in which we must correctly make predictions given only a single example of each new class. In this paper, we explore a method for learning siamese neural networks which employ a unique structure to naturally rank similarity between inputs. Once a network has been tuned, we can then capitalize on powerful discriminative features to generalize the predictive power of the network not just to new data, but to entirely new classes from unknown distributions. Using a convolutional architecture, we are able to achieve strong results which exceed those of other deep learning models with near state-of-the-art performance on one-shot classiÔ¨Åcation tasks.},
	language = {en},
	author = {Koch, Gregory and Zemel, Richard and Salakhutdinov, Ruslan},
	year = {2015},
	url = {https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf},
}


@article{vinyals_matching_2017,
	title = {Matching Networks for One Shot Learning},
	url = {http://arxiv.org/abs/1606.04080},
	abstract = {Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6\% to 93.2\% and from 88.0\% to 93.8\% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.},
	urldate = {2021-06-12},
	author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Kavukcuoglu, Koray and Wierstra, Daan},
	month = dec,
	year = {2017},
	note = {arXiv: 1606.04080},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}


@article{santoro_meta-learning_2016,
	title = {Meta-Learning with Memory-Augmented Neural Networks},
	abstract = {Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of ‚Äúone-shot learning.‚Äù Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefÔ¨Åciently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory locationbased focusing mechanisms.},
	language = {en},
	author = {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy},
	year = {2016},
	url = {https://web.stanford.edu/class/psych209/Readings/Santoro16MetaLearningWithMemAugNNs.pdf},
}



@article{andrychowicz_learning_2016,
	title = {Learning to learn by gradient descent by gradient descent},
	url = {http://arxiv.org/abs/1606.04474},
	abstract = {The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.},
	urldate = {2021-06-12},
	author = {Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W. and Pfau, David and Schaul, Tom and Shillingford, Brendan and de Freitas, Nando},
	month = nov,
	year = {2016},
	note = {arXiv: 1606.04474},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}



@article{snell_prototypical_2017,
	title = {Prototypical Networks for Few-shot Learning},
	url = {http://arxiv.org/abs/1703.05175},
	abstract = {We propose prototypical networks for the problem of few-shot classiÔ¨Åcation, where a classiÔ¨Åer must generalize to new classes not seen in the training set, given only a small number of examples of each new class. Prototypical networks learn a metric space in which classiÔ¨Åcation can be performed by computing distances to prototype representations of each class. Compared to recent approaches for few-shot learning, they reÔ¨Çect a simpler inductive bias that is beneÔ¨Åcial in this limited-data regime, and achieve excellent results. We provide an analysis showing that some simple design decisions can yield substantial improvements over recent approaches involving complicated architectural choices and meta-learning. We further extend prototypical networks to zero-shot learning and achieve state-of-theart results on the CU-Birds dataset.},
	language = {en},
	urldate = {2021-06-11},
	author = {Snell, Jake and Swersky, Kevin and Zemel, Richard S.},
	month = jun,
	year = {2017},
	note = {arXiv: 1703.05175},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}



@article{munkhdalai_meta_2017,
	title = {Meta Networks},
	url = {http://arxiv.org/abs/1703.00837},
	abstract = {Neural networks have been successfully applied in applications with a large amount of labeled data. However, the task of rapid generalization on new concepts with small training data while preserving performances on previously learned ones still presents a significant challenge to neural network models. In this work, we introduce a novel meta learning method, Meta Networks (MetaNet), that learns a meta-level knowledge across tasks and shifts its inductive biases via fast parameterization for rapid generalization. When evaluated on Omniglot and Mini-ImageNet benchmarks, our MetaNet models achieve a near human-level performance and outperform the baseline approaches by up to 6\% accuracy. We demonstrate several appealing properties of MetaNet relating to generalization and continual learning.},
	urldate = {2021-06-12},
	author = {Munkhdalai, Tsendsuren and Yu, Hong},
	month = jun,
	year = {2017},
	note = {arXiv: 1703.00837},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Accepted at ICML 2017 - rewrote: the main section; added: MetaNet algorithmic procedure; performed: Mini-ImageNet evaluation},
}




@article{andrychowicz_learning_2016,
	title = {Learning to learn by gradient descent by gradient descent},
	url = {http://arxiv.org/abs/1606.04474},
	abstract = {The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.},
	urldate = {2021-06-12},
	journal = {arXiv:1606.04474 [cs]},
	author = {Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W. and Pfau, David and Schaul, Tom and Shillingford, Brendan and de Freitas, Nando},
	month = nov,
	year = {2016},
	note = {arXiv: 1606.04474},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing}
}



</script>
</body>

</html>