<!DOCTYPE html>
<html>

<head>
	<title>An Interactive Introduction to Model-Agnostic Meta-Learning üë©‚Äçüî¨</title>
	<meta charset="UTF-8" />
	<link rel="stylesheet" href="build/bundle.css">
</head>

<body>
	<script async src="https://distill.pub/template.v2.js"></script>
	<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

	<script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
	<script defer src="build/bundle.js"></script>

	<d-front-matter>

		<script type="text/json">
			{
				"title": "An Interactive Introduction to Model-Agnostic Meta-Learning",
				"description": "Exploring the world of model-agnostic meta-learning and its extensions.",
				"authors": [
					{
						"author":"Luis M√ºller",
						"authorURL":"https://github.com/pupuis",
						"affiliations": [
							{"name": "NI @ TU Berlin", "url": "https://www.ni.tu-berlin.de/menue/neural_information_processing_group/"}
						]
					},
					{
						"author":"Max Ploner",
						"authorURL":"https://maxploner.de",
						"affiliations": [
							{"name": "NI @ TU Berlin", "url": "https://www.ni.tu-berlin.de/menue/neural_information_processing_group/"},
							{"name": "ML @ HU Berlin", "url": "https://www.informatik.hu-berlin.de/en/forschung-en/gebiete/ml-en"}
						]
					}
				]
			}

		</script>
	</d-front-matter>

	<d-title>
		<!--<h1>An Interactive Introduction to Model-Agnostic Meta-Learning</h1>-->
		<!--<h2>Exploring the world of model-agnostic meta-learning and its extensions.</h2>-->
		<figure class="l-page" style="border-top: 1px solid hsla(0, 0%, 0%, 0.1);">
			<d-figure id="teaser">
				<div class="element is-loading" style="height: 400px"></div>
			</d-figure>
			<figcaption>
				Click button or drag sample onto example to classify the sample.
			</figcaption>
		</figure>
	</d-title>

	<d-byline></d-byline>

	<d-article>

		<p>
			<i style="font-size: .8em;">
				This page is part of a multi-part series on Model-Agnostic Meta-Learning.
				If you are already familiar with the topic, use the menu on the right
				side to jump straight to the part that is of interest for you. Otherwise,
				we suggest you start at the <a href="./">beginning</a>.
			</i>
		</p>

		<aside id="menu" class="menu">
			<div class="element is-loading" style="height: 400px"></div>
		</aside>


		<p>
			If you tried the little exercise above, you probably got a pretty good score.
			Even though you likely have never seen some of the characters,
			you are able to classify them given only a single example, potentially
			without realizing that what you are doing is actually pretty impressive!
		</p>

		<h3>Few-Shot Learning</h3>

		<p>
			Typically, in machine learning we need a lot of examples to be able to
			assign an unseen sample to class. But we do not always have enough data to
			cater this need: A sufficient amount of data may be expensive or even
			impossible to acquire.
			But there is good reasons to believe, that this is not an inherent issue
			of learning.
			Humans, for example, are quite good at generalizing after seeing only a few
			samples. Enabling machine learning methods to achieve the same would allow
			for many new applications and generally reduce the need to collect huge
			datasets.[<b>TODO: reference needed</b>]
		</p>






		<p>
			This research area is called "few-shot learning". It aims to enable models
			to classify unseen sampels after training only one a few examples ("shots").
			The little exercise at the top of the article is an exmaple of such a task.
			The symbols are part of a
			<d-cite bibtex-key="lake_omniglot_2015">dataset called "omniglot"</d-cite>.
			It contains 1623 different characters across 50 alphabets and each character
			has 20 instances drawn by different people. Because of that, the omniglot
			was described as a "transpose" of the well-known MNIST dataset, by the authors
			who originally proposed omniglot as a machine learning dataset.
			<d-cite bibtex-key="lake_one_2011"></d-cite>
			While MNIST contains only a few classes (the digits 0 to 9) and many instances,
			of each class, with omniglot it is vice-versa.
		</p>



		<p>
			By now, you may be asking yourself: How can a model learn from only one example
			(i.e. "one-shot") and why do I even need a dataset like omniglot
			if the model is supposed to learn from one sample?

			Looking at a human learner, we might realize that humans do not learn
			novel concepts "in a vacuum".<d-cite bibtex-key="lake_one_2011"></d-cite>
			Instead, past experience supports the ability to learn the novel concept.
		</p>

		<p>
			While clearly one sample is not enough for a model without prior knowledge,
			we can pretrain models on tasks that we assume to be similar to the target tasks.
			This is a common approach to solving few-shot learning: derive some inductive bias
			from other classes in order to perform better on newly encountered classes.
			This similarity assumption allows the model to collect meta-knowledge:
			knowledge which does not describe a single task, but a distribution of tasks.
			The learning of this meta-knowledge is referred to as "meta-learning".
		</p>

		<figure class="l-page side">
			<d-figure id="fewShotMethods">
				<div class="element is-loading" style="height: 400px"></div>
			</d-figure>
			<figcaption>
				<p>Results of different methods on the omniglot dataset
					(if not stated differently: 1-shot, 20-way;
					some differences in the evaluation procedure exist).
					As usual, accuracy numbers need to be taken with a grain of salt as
					differences in the evaluation method, implementation, and the model
					complexity may a have a non-negligible impact on the performance.
				</p>
				<p id="caption_generative_stroke_model" class="fewShotMethods-reference">
					The generative stroke model was introduced in the paper which also
					introduced omniglot. The model is based on a latent stroke representation
					(including the number and directions of strokes). While it is an
					interesting approach, it can hardly be generalized to other
					few-shot problems.<d-cite bibtex-key="lake_one_2011"></d-cite>
				</p>
				<p id="caption_hierachical_bayesian_program_learning" class="fewShotMethods-reference">
					The same authors improved the model by learning latent
					primitive motor elements and called this process "Hierarchial
					Bayesian Program Learning" (HBPL).
					While the accuracy was greatly increased, it also
					is focused on symbol learning.
					<d-cite bibtex-key="lake_one-shot_2013"></d-cite>
				</p>
				<p id="caption_siamese_nets" class="fewShotMethods-reference">
					Siames Nets consist of two identical networks which produce a latent representation.
					From the representations of two samples, a distance is calculated to
					assess the similarity of the two samples.<d-cite bibtex-key="koch_siamese_2015"></d-cite>
					The result (accuracy of 88.1%) results from a reimplementaion of the method which
					makes it more comparable.
					<d-cite bibtex-key="vinyals_matching_2017"></d-cite>
				</p>
				<p id="caption_matching_nets" class="fewShotMethods-reference">
					Matching Networks also work by comparing new samples to labeled
					examples. They do so by utilizing an attention kernel.
					Though the second version of the paper is cited here,
					it was first published in 2016.
					<d-cite bibtex-key="vinyals_matching_2017"></d-cite>
				</p>

				<p id="caption_prototypical_networks" class="fewShotMethods-reference">
					Prototypical Networks use prototype vectors to represent each class
					in the metric space. The nearest neighbor (i.e. the closest prototype)
					of a sample then determines the prediction.
					<d-cite bibtex-key="snell_prototypical_2017"></d-cite>
				</p>

				<p id="caption_memory_augmented_nets" class="fewShotMethods-reference">
					Memory-Augmented Networks (MANNs) use an external memory to make accurate
					predictions using a small number of samples.
					<d-cite bibtex-key="santoro_meta-learning_2016"></d-cite>
				</p>

				<p id="caption_meta_nets" class="fewShotMethods-reference">
					Meta Networks utilize a base learner (task level) and a meta learner
					as well as a set of slow and rapid weights in order to allow
					meta learning as well as task-specific concepts.
					<d-cite bibtex-key="munkhdalai_meta_2017"></d-cite>
				</p>

			</figcaption>
		</figure>

		<figure class="l-page side">
			<d-figure id="fewShotVenn">
				<div class="element is-loading" style="height: 300px"></div>
			</d-figure>
			<figcaption>
				<p id="caption_lstm_based" class="fewShotMethods-reference">
					Applications of Meta-Learning outside the domain of few-shot learning
					include the optimization of the task-level optimizer using
					a LSTM network.
					<d-cite bibtex-key="andrychowicz_learning_2016"></d-cite>
				</p>
			</figcaption>
		</figure>



		<p>
			Plenty of methods have been proposed in the last years to tackle few-shot
			learning using the meta-learning assumption,
			and many are able to produce decent results.
			In this article, we will focus
			on one of them: "Model-Agnostic Meta-Learning" (MAML).
		</p>

		<h3>Model-Agnostic Meta-Learning</h3>

		<p>
			Before we get started with the explanation of how MAML works,
			we want to take a moment to look at what is Model-Agnostic about MAML.
			In order to understand, why this method is called "model-agnostic", we need
			to look at how the few-shot problem was tackled by other approaches.
			While there are methods, which try to mitigate the issues introduced by the
			the few-shot constraint, many do resort to adopting the meta-learning
			assumption. These methods can broadly be divided into two classes:
			metric-based and model-based approaches.
		</p>
		<p>
			The core idea of metric-based approaches is two compare two samples in a
			latent (metric) space: In this space, samples of the same class are supposed
			to be close to each other, while two samplese from different classes are
			supposed to have a large distance (the notion of a distance is what makes
			the latent space a metric space).
			<d-cite bibtex-key="snell_prototypical_2017"></d-cite>
			<d-cite bibtex-key="koch_siamese_2015"></d-cite>
			<d-cite bibtex-key="vinyals_matching_2017"></d-cite>
		</p>
		<p>
			Model-based approaches are neural architectures which are deliberately designed
			for fast adaption to new tasks without inclining to overfit.
			Memory-Augmented Neural Networks and MetaNet are two examples. Both employ
			an external memory while still maintaining the ability to be trained
			end-to-end.
			<d-cite bibtex-key="santoro_meta-learning_2016"></d-cite>
			<d-cite bibtex-key="munkhdalai_meta_2017"></d-cite>
		</p>

		<p>
			MAML goes a different route: The nerual network is designed the same way
			your usual model might be (in the many-shot case). All the magic happens during the
			optimization. Hence, it is called "optimization-based".
			Unlike, metric-based and model-based approaches, MAML lets
			you choose the model architecture as you like.
			This has the great benefit of being applicable can not only for
			classical supervised learning classification tasks but can also
			for reinforcement learning.
			<d-cite bibtex-key="finn2017modelagnostic"></d-cite>
		</p>
		<p>
			<a href="maml.html">In the next part</a>, you will learn how this is achieved.
		</p>

	</d-article>

	<d-appendix>
	</d-appendix>


	<script type="text/bibliography" src="references.bib"></script>

</body>

</html>
